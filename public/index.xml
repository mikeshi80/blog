<?xml-stylesheet href="/rss.xsl" type="text/xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mike Shi Blog</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Mike Shi Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 30 Jul 2024 14:52:42 +0800</lastBuildDate>
    
        <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    
    
    
        <item>
        <title>在Jetson上安装vLLM</title>
        <link>http://localhost:1313/posts/vllm-on-jetson/</link>
        <pubDate>Tue, 30 Jul 2024 14:52:42 +0800</pubDate>
        
        <guid>http://localhost:1313/posts/vllm-on-jetson/</guid>
        <description>Mike Shi Blog http://localhost:1313/posts/vllm-on-jetson/ -&lt;h1 id=&#34;jetson-orin-agx-下编译相关-vllm-软件&#34;&gt;Jetson Orin AGX 下编译相关 vLLM 软件&lt;/h1&gt;
&lt;h1 id=&#34;编译-pytorch&#34;&gt;编译 PyTorch&lt;/h1&gt;
&lt;p&gt;如果想用 vllm，官方提供的 PyTorch 二进制安装包是不行的，因为它需要用到 distributed 以及 NCCL 的支持，官方提供的包中是不包含这些特性的，甚至一些民间爱好者提供的安装包也只支持了 distributed 而未支持 NCCL，所以需要自行安装。&lt;/p&gt;
&lt;h2 id=&#34;下载必要的工具&#34;&gt;下载必要的工具&lt;/h2&gt;
&lt;p&gt;需要下载安装必要的工具，因为 Jetson Linux 是 Ubuntu 系统，所以直接使用 apt-get 即可。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo apt-get install python3-pip cmake libopenblas-dev libopenmpi-dev
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注：Jetson Linux 自带开发相关的软件包，比如 git, gcc 等，如果是在普通的 PC 版 Linux 下，也可以编译，但需要执行多安装 &lt;code&gt;git build-essential&lt;/code&gt;这两个 package。&lt;/p&gt;
&lt;h2 id=&#34;克隆-pytorch-代码&#34;&gt;克隆 PyTorch 代码&lt;/h2&gt;
&lt;p&gt;系统自带 Git，可以直接用以下命令克隆 PyTorch 代码&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone --recursive http://github.com/pytorch/pytorch
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;由于默认克隆的是当前开发版本，所以通常需要指定一个版本，如 &lt;code&gt;v2.3.1&lt;/code&gt;，则执行&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git checkout v2.3.1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;切换到该版本，也可直接在克隆项目时添加 &lt;code&gt;---branch v2.3.1&lt;/code&gt;参数指定。&lt;/p&gt;
&lt;h2 id=&#34;编译-pytorch-代码&#34;&gt;编译 PyTorch 代码&lt;/h2&gt;
&lt;p&gt;首先确保必须的 Python 包都有安装，并且为了不影响其他环境，先要利用 env 来创建一个虚拟环境。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ pip3 install -r requirements.txt
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ pip3 install scikit-build
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ pip3 install ninja
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;编译代码需要设定一些环境变量，所以最方便的做法是编写一个编译脚本&lt;code&gt;build.sh&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export USE_NCCL&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# export USE_SYSTEM_NCCL=0        # if you do not use system nccl, nvidia-smi may do not work&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export USE_DISTRIBUTED&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;                    &lt;span style=&#34;color:#75715e&#34;&gt;# set 0 if you want to disable OpenMPI backend&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export USE_QNNPACK&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export USE_PYTORCH_QNNPACK&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export TORCH_CUDA_ARCH_LIST&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;5.2;6.1;7.0;7.2;7.5;8.0;8.6;8.7&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export PYTORCH_BUILD_VERSION&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;2.3.1  &lt;span style=&#34;color:#75715e&#34;&gt;# without the leading &amp;#39;v&amp;#39;, e.g. 2.3.0 for PyTorch v2.3.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export PYTORCH_BUILD_NUMBER&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python3 setup.py install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;编译-vllm&#34;&gt;编译 vllm&lt;/h1&gt;
&lt;p&gt;vllm 需要先编译以下几个依赖库：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;triton&lt;/li&gt;
&lt;li&gt;vllm-flash-attn
所以我们将一一介绍。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;triton&#34;&gt;Triton&lt;/h2&gt;
&lt;p&gt;triton 实际可以直接编译，但它需要下载大量文件，而这些文件是在境外服务器的，所以，最好是设置好代理服务器，比如&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export http_proxy&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;http://localhost:7890
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;export https_proxy&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;http://localhost:7890
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后需要将项目 clone 到本地，因为 pypi.org 未提供代码，也只提供了常用平台的二进制安装包，所以直接 pip 是会报错说找不到相应的安装包的。可以按照以下命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/triton-lang/triton.git;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd triton;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install ninja cmake wheel; &lt;span style=&#34;color:#75715e&#34;&gt;# build-time dependencies&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install -e python
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;来进行安装。&lt;/p&gt;
&lt;p&gt;注意，由于要下载好几个 G 的东西，所以非常耗时，需要做好心理准备。&lt;/p&gt;
&lt;h2 id=&#34;vllm-flash-attn&#34;&gt;vllm-flash-attn&lt;/h2&gt;
&lt;p&gt;虽然实际上，没有&lt;code&gt;vllm-flash-attn&lt;/code&gt;，vllm 也会使用内置的 xformers 支持来进行加速。但实际使用下来，在 Orin AGX 下，xformers 是无法正常运行的。所以必须安装&lt;code&gt;vll-flash-attn&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;但该库不能直接从 pypi.org 上下载编译，需要修改部分设置，所以先需要 clone 下来。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone --recurse-submodules https://github.com/vllm-project/flash-attention.git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后修改 setup.py 中的两行：&lt;/p&gt;
&lt;p&gt;一个是&lt;code&gt;if bare_metal_version &amp;gt;= Version(&amp;quot;11.8&amp;quot;):&lt;/code&gt;下，将 90 改成 87。即改为：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cc_flag&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;arch=compute_87,code=sm_87&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因为现在的 vllm 是需要的 PyTorch 版本是 v2.3.0 的，而最新的已经需要 v2.3.1，所以需要修改后面&lt;code&gt;PYTORCH_VERSION&lt;/code&gt;的值从 2.3.1 改成 2.3.0。&lt;/p&gt;
&lt;p&gt;修改完之后执行&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python setup.py install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;进行安装。如果发生内存不足编译失败，可以加&lt;code&gt;MAX_JOBS&lt;/code&gt;来限制最大的并行编译量，比如&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;MAX_JOBS&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; python setup.py install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;来限制最大 4 进程编译。&lt;/p&gt;
&lt;h2 id=&#34;编译-vllm-1&#34;&gt;编译 vllm&lt;/h2&gt;
&lt;p&gt;先将 vllm 的代码 clone 到本地&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone --recurse-submodules https://github.com/vllm-project/vllm.git
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;修改 vllm 的 CMakeLists.txt，将其中的&lt;code&gt;CUDA_SUPPORTED_ARCHS&lt;/code&gt;中，添加 8.7，可以改成如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Plain&#34; data-lang=&#34;Plain&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;set(CUDA_SUPPORTED_ARCHS &amp;#34;7.0;7.5;8.0;8.6;8.7;8.9;9.0&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后可以进行编译&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python setup.py install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;生成-wheel-安装包&#34;&gt;生成 wheel 安装包&lt;/h1&gt;
&lt;p&gt;注意，以上的示例都是最后执行&lt;code&gt;python setup.py install&lt;/code&gt;直接进行安装的。但如果想生成 wheel 安装包供以后再次安装，或分发给其他用户，那么可以将其改为：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python setup.py bdist_wheel
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这样就会在 dist 目录下生成二进制安装包，然后进入该目录，执行&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install xxx.whl &lt;span style=&#34;color:#75715e&#34;&gt;# xxx为该安装包名称&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;- http://localhost:1313/posts/vllm-on-jetson/ - </description>
        </item>
    
    
  </channel>
</rss> 